What are 10 Linux commands you use daily? (Excluding basic ones like ls and cd)

ğŸ“ Short Explanation
This question aims to assess your hands-on experience with Linux, focusing on diagnostic, file manipulation, service management, and automation-related commands that go beyond basic navigation.

âœ… Answer
Here are 10 Linux commands I use regularly, excluding the basics like cd, ls, and pwd:

1. tail -f
tail -f /var/log/nginx/error.log
ğŸ” Monitor log files in real time â€” very useful for debugging issues as they happen.

2. grep
grep -i "timeout" /var/log/app.log
ğŸ” Search through files, logs, or command outputs for specific patterns. I use this to quickly isolate errors.

3. systemctl
systemctl restart nginx
ğŸ› ï¸ Control system services â€” starting, stopping, checking status of systemd services.

4. journalctl
journalctl -u docker.service -f
ğŸ§¾ View logs for systemd-managed services. Especially handy for debugging issues with services like Docker or Kubelet.

5. ps aux | grep
ps aux | grep nginx
ğŸ“‹ List running processes. I use this to find rogue or resource-intensive processes.

6. df -h / du -sh
df -h       # Check available disk space  
du -sh *    # See folder sizes in current directory
ğŸ’¾ Essential for disk space monitoring and cleaning up large files or folders.

7. chmod / chown
chmod +x deploy.sh  
chown ubuntu:ubuntu script.sh
ğŸ” Manage file permissions and ownership â€” very common in CI/CD and provisioning tasks.

8. find
find /var/log -name "*.log" -mtime +7
ğŸ” Locate files based on name, date, type, etc. Great for automating cleanup or audits.

9. curl
curl -I http://localhost:8080
ğŸŒ Test web endpoints, APIs, or service availability from the command line.


----------------------------


/var is almost 90% full. What will be your next steps?

ğŸ“ Short Explanation
This question checks your troubleshooting and disk management skills. The /var directory is commonly used for logs, spools, caches, and runtime data â€” so issues here can break system processes or fill up disks silently.

âœ… Answer
My first step is to identify whatâ€™s consuming the space inside /var. Then I would clean up unnecessary files like rotated logs, caches, or orphaned packages â€” and put alerts or log rotation in place to avoid recurrence.

ğŸ“˜ Detailed Explanation
âœ… Step 1: Inspect Disk Usage Under /var
sudo du -sh /var/* | sort -hr | head -10
This will show which directories inside /var are consuming the most space â€” usually itâ€™s /var/log, /var/cache, or /var/lib/docker.

âœ… Step 2: Clean Log Files
If /var/log is the culprit:

sudo journalctl --vacuum-size=200M
sudo rm -rf /var/log/*.gz /var/log/*.[0-9]
Or truncate large log files:

sudo truncate -s 0 /var/log/syslog
âœ… Step 3: Clear Package Cache
If using apt or yum, clear the package manager cache:

sudo apt clean         # Debian/Ubuntu
sudo yum clean all     # RHEL/CentOS
âœ… Step 4: Check Docker Artifacts
If the server runs containers:

docker system df        # See whatâ€™s taking space
docker system prune -a  # Remove unused containers/images
âš ï¸ Warning: Prune removes unused images and volumes â€” be cautious on production systems.

âœ… Step 5: Consider Moving or Archiving Data
If data in /var is needed but rarely accessed:

Archive old logs to /home or S3
Use logrotate to compress and limit logs:
sudo nano /etc/logrotate.conf

ğŸ§  Why /var Fills Up:
Verbose logging (e.g., failed cron jobs, app debug logs)
Docker images/layers
Orphaned cache files
Email spools or crash dumps
Summary:
Quickly inspect, clean, and automate monitoring. Ensure critical services like journald, docker, and package managers are not starved of space.

------------------------------------------------

Linux Server is slow due to high CPU utilization. How will you fix it?

ğŸ“ Short Explanation
This question assesses your ability to diagnose performance issues, identify root causes, and take targeted actions to reduce CPU load on a production server.

âœ… Answer
I would begin by identifying which processes are consuming the most CPU using tools like top, htop, or pidstat, then analyze whether it's due to a misbehaving application, runaway process, or scheduled job. Based on the findings, Iâ€™d take corrective action â€” either by killing the process, adjusting resource limits, or scaling the workload.

ğŸ“˜ Detailed Explanation
âœ… Step 1: Check Load Average
uptime
Example output:

14:02:03 up  3 days,  4:55,  2 users,  load average: 6.02, 4.33, 2.89
A load average consistently higher than the number of CPU cores indicates overutilization.

âœ… Step 2: Identify CPU-Heavy Processes
top -o %CPU
or more interactively:

htop
This shows which processes are consuming the most CPU.

âœ… Step 3: Drill Down with ps or pidstat
ps -eo pid,ppid,cmd,%cpu,%mem --sort=-%cpu | head
or:

pidstat -u 1 5
These give detailed insight into CPU consumption over time.

âœ… Step 4: Investigate the Cause
Based on what you see, ask:

Is it a specific app (e.g., Java, Python, Node.js)?
Is there a cron job or batch script running?
Is a service misconfigured and looping?
Is it caused by a known bug (e.g., zombie processes)?

âœ… Step 5: Take Corrective Action
Kill or restart runaway process:
kill -9 <pid>
systemctl restart <service>
Scale the application or move workloads
Limit resource usage using nice, cpulimit, or cgroups
Tune app performance (e.g., DB queries, memory leaks)

âœ… Step 6: Check Logs
journalctl -xe
tail -f /var/log/syslog
Logs may reveal:

App crashes
High retry loops
Configuration issues


Refactor long-running or expensive tasks
ğŸ§  Real-Life Examples:
A cron script looping due to a bad condition
A Java app stuck in infinite recursion
Docker containers running unbounded scraping jobs
Antivirus or audit daemon consuming CPU after log floods


-----------------------------------------------------------

How do you find and list the log files older than 7 days in the /var/log folder?

ğŸ“ Short Explanation
This question tests your comfort with Linux file management and log housekeeping â€” a common task for DevOps and sysadmins.

âœ… Answer
You can use the find command with the -mtime option to locate files older than 7 days:

find /var/log -type f -mtime +7
ğŸ“˜ Detailed Explanation
ğŸ” Breakdown of the command:
find: The Linux command to search for files in a directory hierarchy.
/var/log: The target directory that contains log files.
-type f: Limits the search to files (not directories).
-mtime +7: Filters files modified more than 7 days ago.
+7 means strictly older than 7 days.
-7 would mean newer than 7 days.
ğŸ› ï¸ Practical Usage:
If you want to view the size and timestamp of those files:

find /var/log -type f -mtime +7 -exec ls -lh {} \;
If you want to delete those files:

sudo find /var/log -type f -mtime +7 -delete



--------------------------------------------


## Question  
How do you find and remove log files older than 30 days using `-exec` in a folder?

### ğŸ“ Short Explanation  
This version of the task evaluates your comfort with `find -exec`, which is helpful when you want to take specific actions on matched files (like logging or conditional deletion).

## âœ… Answer  
You can use `-exec rm` with `find` to remove log files older than 30 days:

```bash
sudo find /path/to/folder -type f -name "*.log" -mtime +30 -exec rm -f {} \;
```

### ğŸ“˜ Detailed Explanation  

#### ğŸ” Breakdown of the command:
- `sudo`: Used if the directory (like `/var/log`) requires root access.
- `find`: The base command to search files.
- `/path/to/folder`: Replace with your target directory (e.g., `/var/log`).
- `-type f`: Ensures only files are matched.
- `-name "*.log"`: Filters files ending with `.log`.
- `-mtime +30`: Filters files modified **over 30 days ago**.
- `-exec rm -f {} \;`: Executes the `rm -f` command on each matched file:
  - `{}` gets replaced by the current file path.
  - `\;` indicates the end of the command.

---

#### âœ… Example:
```bash
sudo find /var/log -type f -name "*.log" -mtime +30 -exec rm -f {} \;
```

This command will delete all `.log` files in `/var/log` older than 30 days.

---

#### ğŸ§  Bonus Tip â€“ Dry run before delete:
You can review the files that would be deleted:
```bash
find /var/log -type f -name "*.log" -mtime +30 -exec ls -lh {} \;
```

---

> Summary:  
> Using `-exec` gives you fine-grained control over file operations. It's especially useful when you want to extend the logic beyond simple deletion, such as archiving or compressing matched files.

--------------------------------------------------

## Question  
How do you find and delete files larger than 100MB from a given directory?

### ğŸ“ Short Explanation  
This question tests your ability to manage disk space and clean up large files using command-line tools â€” a frequent task for DevOps and Linux admins.

## âœ… Answer  

### ğŸ–¥ï¸ Command (Using `find` and `-exec`)

```bash
find /path/to/directory -type f -size +100M -exec rm -f {} \;
```

---

### ğŸ“˜ Detailed Explanation

#### ğŸ” Breakdown:
- `find`: Linux command to search for files and directories.
- `/path/to/directory`: Replace with your target path (e.g., `/var/log`, `/tmp`).
- `-type f`: Limits results to files only.
- `-size +100M`: Matches files larger than 100 megabytes.
- `-exec rm -f {} \;`: Deletes each matched file:
  - `{}` is replaced by the filename.
  - `\;` ends the `-exec` command.

---

### âœ… Preview Without Deleting (Dry Run)

If you just want to see the files that would be deleted:

```bash
find /path/to/directory -type f -size +100M -exec ls -lh {} \;
```

This prints the size and path of each file over 100MB.

---

### âš ï¸ Best Practices
- Always dry-run before deleting anything in production.
- Consider logging deletions or compressing instead of deleting if space permits.
- Automate safely with cron jobs for specific paths, e.g., `/tmp` or `/var/cache`.

> Summary:  
> Use `find` with `-size +100M` and `-exec rm` to clean up oversized files and free up space. Always preview first to avoid accidental deletion of important files.



----------------------------------------------------------------------



You are asked to monitor multiple services like nginx, sshd, and docker.

Task:

Write a shell script that checks the status of each service.
If a service is stopped, attempt to restart it.
Print a clearly formatted report.
ğŸ“ Short Explanation
This tests your ability to write robust service monitoring automation for multiple services, which is a common expectation in DevOps and SRE roles.

âœ… Answer
ğŸ–¥ï¸ Shell Script: multi_service_monitor.sh
#!/bin/bash

# List of services to monitor
services=("nginx" "sshd" "docker")

# Report Header
echo "-----------------------------------"
echo "  Service Health Check Report"
echo "-----------------------------------"

# Loop through services
for service in "${services[@]}"; do
  if systemctl is-active --quiet "$service"; then
    echo "$service is âœ… RUNNING"
  else
    echo "$service is âŒ STOPPED"
    echo ""
    echo "Attempting to restart $service..."

    systemctl restart "$service" &> /dev/null

    # Check if restart was successful
    if systemctl is-active --quiet "$service"; then
      echo "$service has been âœ… restarted successfully."
    else
      echo "âŒ Failed to restart $service. Manual intervention needed."
    fi
  fi
  echo "-----------------------------------"
done
âœ… Example Output (if docker is down):
-----------------------------------
  Service Health Check Report
-----------------------------------
nginx is âœ… RUNNING
-----------------------------------
sshd is âœ… RUNNING
-----------------------------------
docker is âŒ STOPPED

Attempting to restart docker...
docker has been âœ… restarted successfully.
-----------------------------------
ğŸ“˜ Detailed Explanation
services=(...): An array of services to monitor.
systemctl is-active: Checks if a service is running.
systemctl restart: Tries to restart the service if it's not active.
Conditional Restart Check: After restarting, the script confirms whether the service started successfully.
Output Formatting: Clean section dividers and emojis provide clarity in console or logs.
â° Optional Cron Usage
To run every 10 minutes:

*/10 * * * * /path/to/multi_service_monitor.sh >> /var/log/service_check.log 2>&1


--------------------------------------------------------------------------------

How do you find and delete files larger than 100MB from a given directory?

ğŸ“ Short Explanation
This question tests your ability to manage disk space and clean up large files using command-line tools â€” a frequent task for DevOps and Linux admins.

âœ… Answer
ğŸ–¥ï¸ Command (Using find and -exec)
find /path/to/directory -type f -size +100M -exec rm -f {} \;
ğŸ“˜ Detailed Explanation
ğŸ” Breakdown:
find: Linux command to search for files and directories.
/path/to/directory: Replace with your target path (e.g., /var/log, /tmp).
-type f: Limits results to files only.
-size +100M: Matches files larger than 100 megabytes.
-exec rm -f {} \;: Deletes each matched file:
{} is replaced by the filename.
\; ends the -exec command.
âœ… Preview Without Deleting (Dry Run)
If you just want to see the files that would be deleted:

find /path/to/directory -type f -size +100M -exec ls -lh {} \;
This prints the size and path of each file over 100MB.

âš ï¸ Best Practices
Always dry-run before deleting anything in production.
Consider logging deletions or compressing instead of deleting if space permits.
Automate safely with cron jobs for specific paths, e.g., /tmp or /var/cache.
Summary:
Use find with -size +100M and -exec rm to clean up oversized files and free up space. Always preview first to avoid accidental deletion of important files.


-----------------------------------------------------------------------


Your website is not loading.

Task:
Describe the step-by-step investigation process to identify and fix the issue.

ğŸ“ Short Explanation
This is a high-pressure but common scenario that tests your ability to troubleshoot full-stack issues â€” from DNS and networking to web server and app code.

âœ… Answer
Start from external checks and move inward, layer by layer:

ğŸ§­ 1. Is the site down for everyone or just me?
Use:

curl -I https://yourdomain.com
ping yourdomain.com
Or check with https://downforeveryoneorjustme.com

ğŸŒ 2. DNS Resolution
dig yourdomain.com
nslookup yourdomain.com
âœ… Expect to get the correct IP.
âŒ No IP? Check DNS settings in Route53 (AWS) or other DNS provider.

ğŸ” 3. Is the domain routing to the correct server?
Compare:

curl -v https://yourdomain.com
with server IP. If misrouted, verify DNS records, load balancer config, or CDN rules.

ğŸ“¡ 4. Network/Firewall Check
From your system:
telnet yourdomain.com 443
nc -zv yourdomain.com 80
Check security groups, firewalls, or NACLs in cloud if ports are blocked.
ğŸ–¥ï¸ 5. Is the Web Server running?
SSH into your instance and check:

sudo systemctl status nginx
sudo systemctl status apache2
âŒ If itâ€™s down, restart:

sudo systemctl restart nginx
ğŸ§± 6. Check Application Logs
Look at logs for crash reports or errors:

/var/log/nginx/error.log
/var/log/httpd/error_log
App logs: app.log, stderr, etc.
ğŸ’¾ 7. Check Disk/Memory/CPU
df -h
top or htop
free -m
âœ… Ensure the server isn't unresponsive due to resource exhaustion.

ğŸ”„ 8. Check Backend Services (DB, Cache, etc.)
Your web app may be up, but failing due to:

MySQL/Postgres down
Redis/Memcached connection error
App server crashes
ğŸ” 9. SSL Certificate Issues
curl -Iv https://yourdomain.com
Look for:

SSL certificate problem
If expired, renew via Letâ€™s Encrypt or your CA.

ğŸ§ª 10. Rollback or Revert
If the issue started after a deploy:

Rollback to the previous working build.
Use:
kubectl rollout undo deployment your-deployment
or redeploy old version via your CI/CD.

ğŸ§  Bonus Tip:
Always check uptime monitoring, alerting tools, or dashboards.
Build a runbook for your team for repeated scenarios.
Summary:
Troubleshooting a website that wonâ€™t load requires a methodical approach â€” from DNS to server and app. Think layers: DNS â†’ Network â†’ Web Server â†’ Application â†’ Infrastructure â†’ Dependencies.

